# /path/to/your/project/app.py
# SNNãƒ¢ãƒ‡ãƒ«ã‚’ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã¨ã—ã¦ä½¿ç”¨ã™ã‚‹ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å¯¾è©±AIã®ãƒ—ãƒ­ãƒˆã‚¿ã‚¤ãƒ—
#
# ç›®çš„:
# - ãƒ­ãƒ¼ãƒ‰ãƒãƒƒãƒ— ãƒ•ã‚§ãƒ¼ã‚º2ã€Œ2.4. ãƒ—ãƒ­ãƒˆã‚¿ã‚¤ãƒ—é–‹ç™ºã€ã«å¯¾å¿œã€‚
# - é–‹ç™ºã—ãŸSNNãƒ¢ãƒ‡ãƒ«ã®å¯¾è©±èƒ½åŠ›ã‚’å®Ÿéš›ã«ä½“é¨“ã§ãã‚‹Webã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚’æä¾›ã™ã‚‹ã€‚
#
# å®Ÿè¡Œæ–¹æ³•:
# python app.py --model_path <å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ã‚¹>
# ä¾‹: python app.py --model_path snn_distilled_model.pth

import gradio as gr
import argparse
import time

from main import SNNInferenceEngine

# ã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•°ã¨ã—ã¦æ¨è«–ã‚¨ãƒ³ã‚¸ãƒ³ã‚’ä¿æŒ
inference_engine = None

def chat_function(message: str, history: list) -> str:
    """
    Gradioã®ChatInterfaceã«æ¸¡ã™ãŸã‚ã®ãƒ¡ã‚¤ãƒ³ã®ãƒãƒ£ãƒƒãƒˆå‡¦ç†é–¢æ•°ã€‚

    Args:
        message (str): ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‹ã‚‰ã®æ–°ã—ã„å…¥åŠ›ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã€‚
        history (list): ã“ã‚Œã¾ã§ã®å¯¾è©±å±¥æ­´ã€‚Gradioã«ã‚ˆã£ã¦ç®¡ç†ã•ã‚Œã‚‹ã€‚
                        å½¢å¼: [[user_msg_1, bot_msg_1], [user_msg_2, bot_msg_2], ...]

    Returns:
        str: SNNãƒ¢ãƒ‡ãƒ«ãŒç”Ÿæˆã—ãŸå¿œç­”ãƒ†ã‚­ã‚¹ãƒˆã€‚
    """
    if inference_engine is None:
        return "ã‚¨ãƒ©ãƒ¼: SNNãƒ¢ãƒ‡ãƒ«ãŒãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚’æ­£ã—ã„ãƒ¢ãƒ‡ãƒ«ãƒ‘ã‚¹ã§èµ·å‹•ã—ã¦ãã ã•ã„ã€‚"

    # å¯¾è©±å±¥æ­´ã‚’é€£çµã—ã¦ã€ãƒ¢ãƒ‡ãƒ«ã¸ã®å…¥åŠ›ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ä½œæˆ
    # ã‚·ãƒ³ãƒ—ãƒ«ãªå®Ÿè£…ã¨ã—ã¦ã€æœ€æ–°ã®æ•°ã‚¿ãƒ¼ãƒ³ã®ã¿ã‚’ä½¿ç”¨ã™ã‚‹ã“ã¨ã‚‚å¯èƒ½
    prompt = ""
    for user_msg, bot_msg in history:
        prompt += f"User: {user_msg}\nAssistant: {bot_msg}\n"
    prompt += f"User: {message}\nAssistant:"

    print("-" * 30)
    print(f"Input prompt to SNN:\n{prompt}")

    # SNNãƒ¢ãƒ‡ãƒ«ã§å¿œç­”ã‚’ç”Ÿæˆ
    start_time = time.time()
    generated_text = inference_engine.generate(prompt, max_len=50)
    duration = time.time() - start_time
    
    # "Assistant:" ã®éƒ¨åˆ†ã‚’é™¤å»ã—ã¦æ•´å½¢
    response = generated_text.replace(prompt, "").strip()

    print(f"Generated response: {response}")
    print(f"Inference time: {duration:.4f} seconds")
    print("-" * 30)
    
    return response

def main(args):
    global inference_engine
    
    print(f"Loading SNN model from: {args.model_path}")
    try:
        inference_engine = SNNInferenceEngine(model_path=args.model_path)
        print("âœ… SNN model loaded successfully.")
    except FileNotFoundError:
        print(f"âŒ Error: Model file not found at '{args.model_path}'.")
        print("Please provide a valid path to a trained model using the --model_path argument.")
        return

    # Gradioã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã®æ§‹ç¯‰
    chatbot_interface = gr.ChatInterface(
        fn=chat_function,
        title="ğŸ¤– SNN-based AI Chat Prototype",
        description="é€²åŒ–ã—ãŸBreakthroughSNNãƒ¢ãƒ‡ãƒ«ã¨ã®ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å¯¾è©±ã€‚ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å…¥åŠ›ã—ã¦Enterã‚­ãƒ¼ã‚’æŠ¼ã—ã¦ãã ã•ã„ã€‚",
        chatbot=gr.Chatbot(height=500),
        textbox=gr.Textbox(placeholder="SNNãƒ¢ãƒ‡ãƒ«ã«è©±ã—ã‹ã‘ã‚‹...", container=False, scale=7),
        retry_btn=None,
        undo_btn="å‰Šé™¤",
        clear_btn="ã‚¯ãƒªã‚¢",
    )

    # Webã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®èµ·å‹•
    print("\nStarting Gradio web server...")
    print("Please open the following URL in your browser:")
    chatbot_interface.launch(server_name="0.0.0.0", server_port=args.port)

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="SNNãƒ™ãƒ¼ã‚¹ ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å¯¾è©±AI ãƒ—ãƒ­ãƒˆã‚¿ã‚¤ãƒ—")
    parser.add_argument(
        "--model_path", 
        type=str, 
        required=True, 
        help="å¯¾è©±ã«ä½¿ç”¨ã™ã‚‹å­¦ç¿’æ¸ˆã¿SNNãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ã‚¹ (.pth)"
    )
    parser.add_argument(
        "--port",
        type=int,
        default=7860,
        help="Webã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã‚’èµ·å‹•ã™ã‚‹ãƒãƒ¼ãƒˆç•ªå·"
    )
    args = parser.parse_args()
    main(args)
