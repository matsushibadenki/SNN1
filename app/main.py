# matsushibadenki/snn/app/main.py
# DIã‚³ãƒ³ãƒ†ãƒŠã‚’åˆ©ç”¨ã—ãŸã€Gradioãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å¯¾è©±UIã®èµ·å‹•ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
#
# æ©Ÿèƒ½:
# - DIã‚³ãƒ³ãƒ†ãƒŠã‚’åˆæœŸåŒ–ã—ã€è¨­å®šã‚’èª­ã¿è¾¼ã‚€ã€‚
# - ã‚³ãƒ³ãƒ†ãƒŠã‹ã‚‰å®Œæˆå“ã®ChatServiceã‚’å–å¾—ã—ã¦Gradioã«æ¸¡ã™ã€‚
# - Gradio Blocksã‚’ä½¿ç”¨ã—ã¦ã€ãƒãƒ£ãƒƒãƒˆç”»é¢ã¨ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ çµ±è¨ˆæƒ…å ±ãƒ‘ãƒãƒ«ã‚’æŒã¤UIã‚’æ§‹ç¯‰ã€‚

import gradio as gr
import argparse
import sys
from pathlib import Path

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’Pythonãƒ‘ã‚¹ã«è¿½åŠ 
sys.path.append(str(Path(__file__).parent.parent))

from app.containers import AppContainer

def main():
    parser = argparse.ArgumentParser(description="SNNãƒ™ãƒ¼ã‚¹ ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å¯¾è©±AI ãƒ—ãƒ­ãƒˆã‚¿ã‚¤ãƒ—")
    parser.add_argument("--config", type=str, default="configs/base_config.yaml", help="è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹")
    parser.add_argument("--model_path", type=str, help="ãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ã‚¹ (è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¸Šæ›¸ã)")
    args = parser.parse_args()

    container = AppContainer()
    container.config.from_yaml(args.config)
    if args.model_path:
        container.config.model.path.from_value(args.model_path)

    chat_service = container.chat_service()

    print(f"Loading SNN model from: {container.config.model.path()}")
    print("âœ… SNN model loaded successfully via DI Container.")

    # Gradio Blocks ã‚’ä½¿ç”¨ã—ã¦UIã‚’æ§‹ç¯‰
    with gr.Blocks(theme=gr.themes.Soft(primary_hue="blue", secondary_hue="sky")) as demo:
        gr.Markdown(
            """
            # ğŸ¤– SNN-based AI Chat Prototype
            é€²åŒ–ã—ãŸBreakthroughSNNãƒ¢ãƒ‡ãƒ«ã¨ã®ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å¯¾è©±ã€‚
            å³å´ã®ãƒ‘ãƒãƒ«ã«ã¯ã€æ¨è«–æ™‚é–“ã‚„ç·ã‚¹ãƒ‘ã‚¤ã‚¯æ•°ï¼ˆã‚¨ãƒãƒ«ã‚®ãƒ¼åŠ¹ç‡ã®ä»£ç†æŒ‡æ¨™ï¼‰ãªã©ã®çµ±è¨ˆæƒ…å ±ãŒãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§è¡¨ç¤ºã•ã‚Œã¾ã™ã€‚
            """
        )
        
        initial_stats_md = """
        **Inference Time:** `N/A`
        **Tokens/Second:** `N/A`
        ---
        **Total Spikes:** `N/A`
        **Spikes/Second:** `N/A`
        """

        with gr.Row():
            with gr.Column(scale=2):
                chatbot = gr.Chatbot(label="SNN Chat", height=500, avatar_images=("user.png", "assistant.png"))
            with gr.Column(scale=1):
                stats_display = gr.Markdown(value=initial_stats_md, label="ğŸ“Š Inference Stats")

        with gr.Row():
            msg_textbox = gr.Textbox(
                show_label=False,
                placeholder="SNNãƒ¢ãƒ‡ãƒ«ã«è©±ã—ã‹ã‘ã‚‹...",
                container=False,
                scale=7,
            )
            submit_btn = gr.Button("Send", variant="primary", scale=1)

        def clear_all():
            return [], None, initial_stats_md

        # `submit` ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã®å®šç¾©
        submit_btn.click(
            fn=chat_service.stream_response,
            inputs=[msg_textbox, chatbot],
            outputs=[chatbot, stats_display]
        )
        # ãƒ†ã‚­ã‚¹ãƒˆãƒœãƒƒã‚¯ã‚¹ã‚’ã‚¯ãƒªã‚¢ã™ã‚‹ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’è¿½åŠ 
        submit_btn.click(fn=lambda: "", inputs=None, outputs=msg_textbox)

        # Enterã‚­ãƒ¼ã§ã®é€ä¿¡
        msg_textbox.submit(
            fn=chat_service.stream_response,
            inputs=[msg_textbox, chatbot],
            outputs=[chatbot, stats_display]
        )
        msg_textbox.submit(fn=lambda: "", inputs=None, outputs=msg_textbox)

    # Webã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®èµ·å‹•
    print("\nStarting Gradio web server...")
    print(f"Please open http://{container.config.app.server_name()}:{container.config.app.server_port()} in your browser.")
    demo.launch(
        server_name=container.config.app.server_name(),
        server_port=container.config.app.server_port(),
    )

if __name__ == "__main__":
    main()
