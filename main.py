# /path/to/your/project/main.py
# SNNãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’ã¨æ¨è«–ã‚’å®Ÿè¡Œã™ã‚‹ãŸã‚ã®ãƒ¡ã‚¤ãƒ³ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
#
# å…ƒãƒ•ã‚¡ã‚¤ãƒ«:
# - train_text_snn.py (å­¦ç¿’éƒ¨åˆ†)
# - inference.py (æ¨è«–éƒ¨åˆ†)
# - snn_breakthrough.py (å®Ÿè¡Œãƒ–ãƒ­ãƒƒã‚¯)
# ã‚’çµ±åˆã—ã€snn_core.pyã®ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã‚’ä½¿ç”¨ã™ã‚‹ã‚ˆã†ã«å¤‰æ›´

import torch
import torch.nn as nn
from torch.utils.data import Dataset, DataLoader
from collections import Counter
import itertools
from typing import List, Tuple, Dict
import os

# snn_coreã‹ã‚‰ä¸»è¦ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from snn_core import BreakthroughSNN, BreakthroughTrainer

# ----------------------------------------
# 1. ãƒ‡ãƒ¼ã‚¿æº–å‚™ã¨èªå½™ã®æ§‹ç¯‰
# ----------------------------------------

class Vocabulary:
    """ãƒ†ã‚­ã‚¹ãƒˆã¨IDã‚’ç›¸äº’å¤‰æ›ã™ã‚‹ãŸã‚ã®èªå½™ã‚¯ãƒ©ã‚¹"""
    def __init__(self, all_texts: List[Tuple[str, int]]):
        self.word2idx = {"<PAD>": 0, "<UNK>": 1, "<START>": 2, "<END>": 3}
        self.idx2word = {v: k for k, v in self.word2idx.items()}
        if all_texts:
            self._build_vocab(all_texts)

    def _build_vocab(self, all_texts: List[Tuple[str, int]]):
        all_words = list(itertools.chain.from_iterable(txt.lower().split() for txt, _ in all_texts))
        for word in Counter(all_words).keys():
            if word not in self.word2idx:
                self.word2idx[word] = len(self.word2idx)
        self.idx2word = {v: k for k, v in self.word2idx.items()}
    
    def encode(self, text: str) -> List[int]:
        return [self.word2idx.get(word.lower(), self.word2idx["<UNK>"]) for word in text.split()]
    
    @property
    def vocab_size(self) -> int:
        return len(self.word2idx)

class TextDataset(Dataset):
    """ãƒ†ã‚­ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ"""
    def __init__(self, data: List[Tuple[str, int]], vocab: Vocabulary, max_len: int = 32):
        self.data = data
        self.vocab = vocab
        self.max_len = max_len
    
    def __len__(self):
        return len(self.data)
    
    def __getitem__(self, idx):
        text, label = self.data[idx]
        encoded_text = self.vocab.encode(text)[:self.max_len]
        padded_text = encoded_text + [self.vocab.word2idx["<PAD>"]] * (self.max_len - len(encoded_text))
        return torch.tensor(padded_text), torch.tensor(label, dtype=torch.long)

# ----------------------------------------
# 2. æ¨è«–ã‚¨ãƒ³ã‚¸ãƒ³
# ----------------------------------------

class SNNInferenceEngine:
    def __init__(self, model_path: str, device: str = "cpu"):
        if not os.path.exists(model_path):
            raise FileNotFoundError(f"ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {model_path}")
        
        self.device = torch.device(device)
        checkpoint = torch.load(model_path, map_location=self.device)
        
        self.vocab = checkpoint['vocab']
        config = checkpoint['config']
        
        self.model = BreakthroughSNN(
            vocab_size=self.vocab.vocab_size,
            d_model=config['d_model'],
            num_layers=config['num_layers'],
            time_steps=config['time_steps']
        ).to(self.device)
        self.model.load_state_dict(checkpoint['model_state_dict'])
        self.model.eval()
        
        self.class_labels = {0: "ãƒã‚¬ãƒ†ã‚£ãƒ–", 1: "ãƒã‚¸ãƒ†ã‚£ãƒ–"}

    def predict(self, text: str) -> str:
        print(f"\nå…¥åŠ›æ–‡ç« : '{text}'")
        encoded_text = self.vocab.encode(text)[:32]
        padded_text = encoded_text + [self.vocab.word2idx["<PAD>"]] * (32 - len(encoded_text))
        input_tensor = torch.tensor([padded_text]).to(self.device)
        
        with torch.no_grad():
            outputs = self.model(input_tensor)
        
        _, predicted_idx = torch.max(outputs.data, 1)
        return self.class_labels[predicted_idx.item()]

# ----------------------------------------
# 3. å®Ÿè¡Œãƒ–ãƒ­ãƒƒã‚¯
# ----------------------------------------

def train():
    """ãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’ã‚’å®Ÿè¡Œ"""
    print("ğŸš€ é©æ–°çš„SNNã‚·ã‚¹ãƒ†ãƒ ã®è¨“ç·´é–‹å§‹")
    
    # ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿
    TRAIN_DATA = [
        ("this movie was terrible", 0), ("i absolutely loved it", 1),
        ("a complete disappointment", 0), ("one of the best films", 1),
        ("the plot was confusing", 0), ("a heartwarming story", 1),
        ("i would not recommend this", 0), ("an unforgettable experience", 1),
        ("what a mess", 0), ("simply fantastic", 1)
    ]
    
    # èªå½™æ§‹ç¯‰
    vocab = Vocabulary(TRAIN_DATA)
    
    # ãƒ¢ãƒ‡ãƒ«è¨­å®š
    config = {'d_model': 64, 'num_layers': 2, 'time_steps': 10}
    model = BreakthroughSNN(vocab_size=vocab.vocab_size, **config)
    trainer = BreakthroughTrainer(model)
    
    # ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼
    dataset = TextDataset(TRAIN_DATA, vocab)
    dataloader = DataLoader(dataset, batch_size=2, shuffle=True)
    
    # å­¦ç¿’ãƒ«ãƒ¼ãƒ—
    for epoch in range(20):
        for input_ids, labels in dataloader:
            # ãƒ©ãƒ™ãƒ«ã‚’ãƒ€ãƒŸãƒ¼ã®ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã«å¤‰æ›ï¼ˆæå¤±è¨ˆç®—ã®ãŸã‚ï¼‰
            target_ids = labels.unsqueeze(1).repeat(1, 32)
            metrics = trainer.train_step(input_ids, target_ids)
        if (epoch + 1) % 5 == 0:
            print(f"Epoch {epoch+1}: {metrics}")
            
    # ãƒ¢ãƒ‡ãƒ«ä¿å­˜
    model_path = "breakthrough_snn_model.pth"
    torch.save({
        'model_state_dict': model.state_dict(),
        'vocab': vocab,
        'config': config
    }, model_path)
    print(f"\nâœ… å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã‚’ '{model_path}' ã«ä¿å­˜ã—ã¾ã—ãŸã€‚")

def inference():
    """å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã§æ¨è«–ã‚’å®Ÿè¡Œ"""
    MODEL_FILE_PATH = "breakthrough_snn_model.pth"
    
    try:
        engine = SNNInferenceEngine(model_path=MODEL_FILE_PATH)
        test_sentences = [
            "an unforgettable experience truly a masterpiece",
            "the plot was confusing and the characters were boring",
            "i will watch it again",
            "what a mess"
        ]
        
        for sentence in test_sentences:
            prediction = engine.predict(sentence)
            print(f"æ¨è«–çµæœ: {prediction}")

    except FileNotFoundError as e:
        print(e)
        print("ã‚¨ãƒ©ãƒ¼: å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãŒå¿…è¦ã§ã™ã€‚å…ˆã« 'train' ãƒ¢ãƒ¼ãƒ‰ã§å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")

if __name__ == "__main__":
    import sys
    if len(sys.argv) > 1 and sys.argv[1] == "train":
        train()
    elif len(sys.argv) > 1 and sys.argv[1] == "inference":
        inference()
    else:
        print("ä½¿ã„æ–¹: python main.py [train|inference]")
        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§å­¦ç¿’ã‚’å®Ÿè¡Œ
        print("\n--- ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®å­¦ç¿’ãƒ¢ãƒ¼ãƒ‰ã‚’å®Ÿè¡Œã—ã¾ã™ ---")
        train()