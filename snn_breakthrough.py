# /path/to/your/project/snn_breakthrough.py
# SNNã§ANNã‚’è¶…è¶Šã™ã‚‹ãŸã‚ã®é©æ–°çš„å®Ÿè£…
# 
# ä¸»è¦é©æ–°:
# 1. Spiking State Space Model (Spiking-SSM) å®Ÿè£…
# 2. Multi-Threshold Adaptive Neurons
# 3. Temporal Attention Mechanism
# 4. Event-Driven Computation Engine

import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader
import numpy as np
from spikingjelly.activation_based import neuron, surrogate, functional
import math
from typing import List, Tuple, Optional, Dict, Any
import time

# ----------------------------------------
# 1. æ¬¡ä¸–ä»£ã‚¹ãƒ‘ã‚¤ã‚­ãƒ³ã‚°ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ãƒ¢ãƒ‡ãƒ«
# ----------------------------------------

class MultiThresholdLIF(nn.Module):
    """è¤‡æ•°é–¾å€¤ã‚’æŒã¤é©å¿œçš„LIFãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³"""
    
    def __init__(self, features: int, num_thresholds: int = 3, tau: float = 2.0):
        super().__init__()
        self.features = features
        self.num_thresholds = num_thresholds
        
        # é©å¿œçš„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        self.tau = nn.Parameter(torch.full((features,), tau))
        self.thresholds = nn.Parameter(torch.linspace(0.5, 1.5, num_thresholds).unsqueeze(0).repeat(features, 1))
        self.reset_values = nn.Parameter(torch.zeros(features, num_thresholds))
        
        # è†œé›»ä½ã¨çŠ¶æ…‹
        self.register_buffer('v_mem', torch.zeros(1, features))
        self.register_buffer('adaptation', torch.zeros(1, features))
        
        # ä»£ç†å‹¾é…é–¢æ•°
        self.surrogate_function = surrogate.ATan(alpha=2.0)
        
    def forward(self, x: torch.Tensor) -> torch.Tensor:
        batch_size = x.shape[0]
        
        if self.v_mem.shape[0] != batch_size:
            self.v_mem = self.v_mem.expand(batch_size, -1).contiguous()
            self.adaptation = self.adaptation.expand(batch_size, -1).contiguous()
        
        # è†œé›»ä½æ›´æ–°ï¼ˆé©å¿œæ€§ã‚’å«ã‚€ï¼‰
        decay = torch.exp(-1.0 / torch.clamp(self.tau, min=0.1))
        self.v_mem = self.v_mem * decay + x - self.adaptation * 0.1
        
        # è¤‡æ•°é–¾å€¤ã§ã®ã‚¹ãƒ‘ã‚¤ã‚¯åˆ¤å®š
        spikes = torch.zeros_like(x)
        for i in range(self.num_thresholds):
            threshold = self.thresholds[:, i].unsqueeze(0)
            spike_mask = self.surrogate_function(self.v_mem - threshold)
            spikes += spike_mask * (i + 1)  # é–¾å€¤ãƒ¬ãƒ™ãƒ«ã«å¿œã˜ãŸé‡ã¿ä»˜ã‘
            
            # ãƒªã‚»ãƒƒãƒˆå‡¦ç†
            reset_mask = (spike_mask > 0.5).float()
            self.v_mem = self.v_mem * (1 - reset_mask) + self.reset_values[:, i].unsqueeze(0) * reset_mask
        
        # é©å¿œæ©Ÿæ§‹ã®æ›´æ–°
        self.adaptation = self.adaptation * 0.95 + (spikes > 0).float() * 0.05
        
        return spikes / self.num_thresholds  # æ­£è¦åŒ–

class AdaptiveSTDPSynapse(nn.Module):
    """STDPå­¦ç¿’å‰‡ã‚’å«ã‚€é©å¿œçš„ã‚·ãƒŠãƒ—ã‚¹"""
    
    def __init__(self, in_features: int, out_features: int):
        super().__init__()
        self.in_features = in_features
        self.out_features = out_features
        
        # ã‚·ãƒŠãƒ—ã‚¹é‡ã¿
        self.weight = nn.Parameter(torch.randn(out_features, in_features) * 0.1)
        
        # STDPãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        self.learning_rate = 0.01
        self.tau_plus = 20.0
        self.tau_minus = 20.0
        self.a_plus = 1.0
        self.a_minus = -0.5
        
        # ã‚¹ãƒ‘ã‚¤ã‚¯å±¥æ­´ï¼ˆSTDPè¨ˆç®—ç”¨ï¼‰
        self.register_buffer('pre_spike_trace', torch.zeros(1, in_features))
        self.register_buffer('post_spike_trace', torch.zeros(1, out_features))
        
    def forward(self, x: torch.Tensor, apply_stdp: bool = False) -> torch.Tensor:
        batch_size = x.shape[0]
        
        # åŸºæœ¬çš„ãªç·šå½¢å¤‰æ›
        output = F.linear(x, self.weight)
        
        if apply_stdp and self.training:
            # STDPã«ã‚ˆã‚‹é‡ã¿æ›´æ–°
            self._update_weights_stdp(x, output)
        
        return output
    
    def _update_weights_stdp(self, pre_spikes: torch.Tensor, post_spikes: torch.Tensor):
        """STDPå­¦ç¿’å‰‡ã«ã‚ˆã‚‹é‡ã¿æ›´æ–°"""
        # ã‚¹ãƒ‘ã‚¤ã‚¯ãƒˆãƒ¬ãƒ¼ã‚¹ã®æ›´æ–°
        self.pre_spike_trace = self.pre_spike_trace * math.exp(-1/self.tau_plus) + pre_spikes.mean(0)
        self.post_spike_trace = self.post_spike_trace * math.exp(-1/self.tau_minus) + post_spikes.mean(0)
        
        # STDPé‡ã¿æ›´æ–°
        # LTP (Long-Term Potentiation)
        ltp = self.a_plus * torch.outer(post_spikes.mean(0), self.pre_spike_trace)
        
        # LTD (Long-Term Depression)  
        ltd = self.a_minus * torch.outer(self.post_spike_trace, pre_spikes.mean(0))
        
        # é‡ã¿æ›´æ–°
        weight_update = self.learning_rate * (ltp + ltd)
        self.weight.data += weight_update
        
        # é‡ã¿ã®æ­£è¦åŒ–ã¨ã‚¯ãƒªãƒƒãƒ”ãƒ³ã‚°
        self.weight.data = torch.clamp(self.weight.data, -2.0, 2.0)

# ----------------------------------------
# 2. Spiking State Space Model (é©æ–°çš„ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£)
# ----------------------------------------

class SpikingSSMLayer(nn.Module):
    """ã‚¹ãƒ‘ã‚¤ã‚­ãƒ³ã‚°çŠ¶æ…‹ç©ºé–“ãƒ¢ãƒ‡ãƒ« - ç·šå½¢è¨ˆç®—é‡ã§é•·æœŸä¾å­˜é–¢ä¿‚ã‚’å‡¦ç†"""
    
    def __init__(self, d_model: int, d_state: int = 64, dt_rank: int = None):
        super().__init__()
        self.d_model = d_model
        self.d_state = d_state
        self.dt_rank = dt_rank or math.ceil(d_model / 16)
        
        # SSMãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        self.A = nn.Parameter(torch.randn(d_state))  # çŠ¶æ…‹è¡Œåˆ—
        self.B = nn.Parameter(torch.randn(d_state, d_model))  # å…¥åŠ›è¡Œåˆ—
        self.C = nn.Parameter(torch.randn(d_model, d_state))  # å‡ºåŠ›è¡Œåˆ—
        self.D = nn.Parameter(torch.randn(d_model))  # ã‚¹ã‚­ãƒƒãƒ—æ¥ç¶š
        
        # æ™‚é–“ä¾å­˜ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        self.dt_proj = nn.Linear(d_model, self.dt_rank, bias=False)
        self.dt_bias = nn.Parameter(torch.randn(self.dt_rank))
        
        # ã‚¹ãƒ‘ã‚¤ã‚­ãƒ³ã‚°è¦ç´ 
        self.input_lif = MultiThresholdLIF(d_model)
        self.output_lif = MultiThresholdLIF(d_model)
        
        # çŠ¶æ…‹ãƒãƒƒãƒ•ã‚¡
        self.register_buffer('h_state', torch.zeros(1, d_state))
        
    def forward(self, x: torch.Tensor) -> torch.Tensor:
        """
        x: (batch, seq_len, d_model) ã¾ãŸã¯ (batch, time_steps, seq_len, d_model)
        """
        if x.dim() == 4:  # ã‚¹ãƒ‘ã‚¤ã‚¯ã‚·ãƒ¼ã‚±ãƒ³ã‚¹
            return self._forward_spike_sequence(x)
        else:  # é€šå¸¸ã®ã‚·ãƒ¼ã‚±ãƒ³ã‚¹
            return self._forward_sequence(x)
    
    def _forward_spike_sequence(self, x: torch.Tensor) -> torch.Tensor:
        batch_size, time_steps, seq_len, d_model = x.shape
        outputs = []
        
        # çŠ¶æ…‹ã®åˆæœŸåŒ–
        if self.h_state.shape[0] != batch_size:
            self.h_state = self.h_state.expand(batch_size, -1).contiguous()
        
        for t in range(time_steps):
            x_t = x[:, t, :, :]  # (batch, seq_len, d_model)
            
            # ã‚¹ãƒ‘ã‚¤ã‚¯å‰å‡¦ç†
            x_spike = self.input_lif(x_t.reshape(-1, d_model)).reshape(batch_size, seq_len, d_model)
            
            # SSMå‡¦ç†
            out_t = self._ssm_step(x_spike)
            
            # ã‚¹ãƒ‘ã‚¤ã‚¯å¾Œå‡¦ç†
            out_spike = self.output_lif(out_t.reshape(-1, d_model)).reshape(batch_size, seq_len, d_model)
            outputs.append(out_spike)
        
        return torch.stack(outputs, dim=1)
    
    def _forward_sequence(self, x: torch.Tensor) -> torch.Tensor:
        batch_size, seq_len, d_model = x.shape
        
        # ä¸¦åˆ—SSMè¨ˆç®—ï¼ˆåŠ¹ç‡åŒ–ç‰ˆï¼‰
        return self._parallel_ssm(x)
    
    def _ssm_step(self, x: torch.Tensor) -> torch.Tensor:
        """å˜ä¸€ã‚¹ãƒ†ãƒƒãƒ—ã®SSMè¨ˆç®—"""
        batch_size, seq_len, d_model = x.shape
        
        # å‹•çš„æ™‚é–“ã‚¹ãƒ†ãƒƒãƒ—è¨ˆç®—
        dt = F.softplus(self.dt_proj(x) + self.dt_bias.unsqueeze(0).unsqueeze(0))
        
        # é›¢æ•£åŒ–ï¼ˆZero-Order Holdï¼‰
        dt_expanded = dt.unsqueeze(-1)  # (batch, seq_len, dt_rank, 1)
        A_expanded = self.A.unsqueeze(0).unsqueeze(0).unsqueeze(0)  # (1, 1, 1, d_state)
        
        # ä¸¦åˆ—è¨ˆç®—ã®ãŸã‚ç°¡ç•¥åŒ–
        discretized_A = torch.exp(dt_expanded * A_expanded).mean(dim=2)  # (batch, seq_len, d_state)
        
        outputs = []
        for i in range(seq_len):
            x_i = x[:, i, :]  # (batch, d_model)
            dt_i = dt[:, i, :].mean(dim=-1, keepdim=True)  # (batch, 1)
            
            # çŠ¶æ…‹æ›´æ–°
            self.h_state = discretized_A[:, i, :] * self.h_state + dt_i * torch.matmul(x_i, self.B.T)
            
            # å‡ºåŠ›è¨ˆç®—
            y_i = torch.matmul(self.h_state, self.C.T) + self.D * x_i
            outputs.append(y_i)
        
        return torch.stack(outputs, dim=1)
    
    def _parallel_ssm(self, x: torch.Tensor) -> torch.Tensor:
        """ä¸¦åˆ—SSMè¨ˆç®—ï¼ˆæ¨è«–ç”¨æœ€é©åŒ–ç‰ˆï¼‰"""
        batch_size, seq_len, d_model = x.shape
        
        # ç°¡ç•¥åŒ–ã•ã‚ŒãŸä¸¦åˆ—è¨ˆç®—
        # å®Ÿè£…ã®è©³ç´°ã¯çœç•¥ã—ã€æ¦‚å¿µçš„ãªå‡¦ç†ã‚’ç¤ºã™
        
        # ç•³ã¿è¾¼ã¿ãƒ™ãƒ¼ã‚¹ã®åŠ¹ç‡çš„å®Ÿè£…
        conv_kernel = self._compute_conv_kernel(seq_len)
        
        # 1Dã‚³ãƒ³ãƒœãƒªãƒ¥ãƒ¼ã‚·ãƒ§ãƒ³ã¨ã—ã¦å‡¦ç†
        x_padded = F.pad(x.transpose(1, 2), (conv_kernel.shape[-1] - 1, 0))
        output = F.conv1d(x_padded, conv_kernel, groups=d_model)
        
        return output.transpose(1, 2)[:, :seq_len, :]
    
    def _compute_conv_kernel(self, seq_len: int) -> torch.Tensor:
        """ç•³ã¿è¾¼ã¿ã‚«ãƒ¼ãƒãƒ«ã®è¨ˆç®—"""
        # ç°¡ç•¥åŒ–å®Ÿè£…
        kernel = torch.exp(-torch.arange(seq_len, dtype=torch.float) * 0.1)
        return kernel.unsqueeze(0).unsqueeze(0).repeat(self.d_model, 1, 1)

# ----------------------------------------
# 3. æ™‚é–“çš„ã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³æ©Ÿæ§‹
# ----------------------------------------

class TemporalSpikeAttention(nn.Module):
    """æ™‚é–“æƒ…å ±ã‚’æ´»ç”¨ã—ãŸã‚¹ãƒ‘ã‚¤ã‚¯ãƒ™ãƒ¼ã‚¹ã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³"""
    
    def __init__(self, d_model: int, num_heads: int = 8, spike_threshold: float = 0.5):
        super().__init__()
        self.d_model = d_model
        self.num_heads = num_heads
        self.head_dim = d_model // num_heads
        self.spike_threshold = spike_threshold
        
        # ã‚¯ã‚¨ãƒªã€ã‚­ãƒ¼ã€ãƒãƒªãƒ¥ãƒ¼ã®æŠ•å½±
        self.q_proj = AdaptiveSTDPSynapse(d_model, d_model)
        self.k_proj = AdaptiveSTDPSynapse(d_model, d_model)
        self.v_proj = AdaptiveSTDPSynapse(d_model, d_model)
        self.out_proj = AdaptiveSTDPSynapse(d_model, d_model)
        
        # æ™‚é–“çš„é‡ã¿
        self.temporal_embedding = nn.Parameter(torch.randn(1024, d_model))  # æœ€å¤§1024æ™‚åˆ»
        
        # ã‚¹ãƒ‘ã‚¤ã‚­ãƒ³ã‚°è¦ç´ 
        self.attention_lif = MultiThresholdLIF(d_model)
        
    def forward(self, x: torch.Tensor, temporal_mask: Optional[torch.Tensor] = None) -> torch.Tensor:
        """
        x: (batch, time_steps, seq_len, d_model) for spike sequences
           or (batch, seq_len, d_model) for regular sequences
        """
        if x.dim() == 4:
            return self._spike_attention(x, temporal_mask)
        else:
            return self._regular_attention(x)
    
    def _spike_attention(self, x: torch.Tensor, temporal_mask: Optional[torch.Tensor] = None) -> torch.Tensor:
        batch_size, time_steps, seq_len, d_model = x.shape
        
        # æ™‚é–“çš„æƒ…å ±ã‚’çµ±åˆ
        time_emb = self.temporal_embedding[:time_steps].unsqueeze(0).unsqueeze(2)
        x_with_time = x + time_emb
        
        # å„æ™‚åˆ»ã§ã®ã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³è¨ˆç®—
        outputs = []
        for t in range(time_steps):
            x_t = x_with_time[:, t, :, :]  # (batch, seq_len, d_model)
            
            # ã‚¹ãƒ‘ã‚¤ã‚¯ãƒ™ãƒ¼ã‚¹ã‚¯ã‚¨ãƒªã€ã‚­ãƒ¼ã€ãƒãƒªãƒ¥ãƒ¼
            q = self.q_proj(x_t.reshape(-1, d_model)).reshape(batch_size, seq_len, self.num_heads, self.head_dim)
            k = self.k_proj(x_t.reshape(-1, d_model)).reshape(batch_size, seq_len, self.num_heads, self.head_dim)
            v = self.v_proj(x_t.reshape(-1, d_model)).reshape(batch_size, seq_len, self.num_heads, self.head_dim)
            
            # ã‚¹ãƒ‘ã‚¤ã‚¯é–¾å€¤å‡¦ç†
            q_spike = (q > self.spike_threshold).float()
            k_spike = (k > self.spike_threshold).float()
            
            # ã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³ã‚¹ã‚³ã‚¢è¨ˆç®—ï¼ˆã‚¹ãƒ‘ã‚¤ã‚¯ç›¸é–¢ãƒ™ãƒ¼ã‚¹ï¼‰
            scores = torch.einsum('bihd,bjhd->bhij', q_spike, k_spike) / math.sqrt(self.head_dim)
            
            # æ™‚é–“çš„ãƒã‚¹ã‚¯é©ç”¨
            if temporal_mask is not None:
                scores += temporal_mask[:, t, :, :].unsqueeze(1) * -1e9
            
            # ã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³é‡ã¿
            attn_weights = F.softmax(scores, dim=-1)
            
            # å€¤ã¨ã®çµ±åˆ
            out = torch.einsum('bhij,bjhd->bihd', attn_weights, v)
            out = out.reshape(batch_size, seq_len, d_model)
            
            # å‡ºåŠ›æŠ•å½±ã¨ã‚¹ãƒ‘ã‚¤ã‚¯å‡¦ç†
            out = self.out_proj(out.reshape(-1, d_model)).reshape(batch_size, seq_len, d_model)
            out = self.attention_lif(out.reshape(-1, d_model)).reshape(batch_size, seq_len, d_model)
            
            outputs.append(out)
        
        return torch.stack(outputs, dim=1)

# ----------------------------------------
# 4. ã‚¤ãƒ™ãƒ³ãƒˆé§†å‹•è¨ˆç®—ã‚¨ãƒ³ã‚¸ãƒ³
# ----------------------------------------

class EventDrivenComputeEngine(nn.Module):
    """ã‚¹ãƒ‘ã‚¤ã‚¯ãŒç™ºç”Ÿã—ãŸæ™‚ã®ã¿è¨ˆç®—ã‚’è¡Œã†åŠ¹ç‡çš„ã‚¨ãƒ³ã‚¸ãƒ³"""
    
    def __init__(self, model: nn.Module, spike_threshold: float = 0.01):
        super().__init__()
        self.model = model
        self.spike_threshold = spike_threshold
        
        # è¨ˆç®—çµ±è¨ˆ
        self.total_computations = 0
        self.active_computations = 0
        
    def forward(self, x: torch.Tensor) -> torch.Tensor:
        """ã‚¤ãƒ™ãƒ³ãƒˆé§†å‹•ã§ã®å‰å‘ãè¨ˆç®—"""
        if x.dim() == 4:  # ã‚¹ãƒ‘ã‚¤ã‚¯ã‚·ãƒ¼ã‚±ãƒ³ã‚¹
            return self._event_driven_forward(x)
        else:
            return self.model(x)
    
    def _event_driven_forward(self, x: torch.Tensor) -> torch.Tensor:
        batch_size, time_steps, seq_len, d_model = x.shape
        
        # å‡ºåŠ›ãƒãƒƒãƒ•ã‚¡ã®åˆæœŸåŒ–
        outputs = torch.zeros_like(x)
        
        for t in range(time_steps):
            x_t = x[:, t, :, :]
            
            # ã‚¹ãƒ‘ã‚¤ã‚¯ã‚¤ãƒ™ãƒ³ãƒˆã®æ¤œå‡º
            spike_mask = (torch.abs(x_t) > self.spike_threshold).any(dim=-1)  # (batch, seq_len)
            
            # ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãªä½ç½®ã®ã¿è¨ˆç®—
            if spike_mask.any():
                active_indices = torch.nonzero(spike_mask, as_tuple=False)
                active_inputs = x_t[spike_mask]
                
                if len(active_inputs) > 0:
                    # è¨ˆç®—å®Ÿè¡Œ
                    active_outputs = self.model(active_inputs.reshape(-1, d_model))
                    
                    # çµæœã‚’å…ƒã®ä½ç½®ã«æˆ»ã™
                    for i, (batch_idx, seq_idx) in enumerate(active_indices):
                        start_idx = i * d_model
                        end_idx = start_idx + d_model
                        outputs[batch_idx, t, seq_idx, :] = active_outputs[start_idx:end_idx]
                    
                    # çµ±è¨ˆæ›´æ–°
                    self.active_computations += len(active_inputs)
            
            self.total_computations += batch_size * seq_len
        
        return outputs
    
    def get_efficiency_metrics(self) -> Dict[str, float]:
        """è¨ˆç®—åŠ¹ç‡ã®çµ±è¨ˆã‚’å–å¾—"""
        if self.total_computations == 0:
            return {"efficiency": 0.0, "active_ratio": 0.0}
        
        efficiency = (self.total_computations - self.active_computations) / self.total_computations
        active_ratio = self.active_computations / self.total_computations
        
        return {
            "efficiency": efficiency * 100,  # å‰Šæ¸›ã•ã‚ŒãŸè¨ˆç®—ã®å‰²åˆ
            "active_ratio": active_ratio * 100,  # ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãªè¨ˆç®—ã®å‰²åˆ
            "total_ops": self.total_computations,
            "active_ops": self.active_computations
        }

# ----------------------------------------
# 5. çµ±åˆã•ã‚ŒãŸæ¬¡ä¸–ä»£SNNã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£
# ----------------------------------------

class BreakthroughSNN(nn.Module):
    """ANNã‚’è¶…è¶Šã™ã‚‹ã“ã¨ã‚’ç›®æŒ‡ã—ãŸé©æ–°çš„SNNã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£"""
    
    def __init__(
        self,
        vocab_size: int,
        d_model: int = 512,
        d_state: int = 128,
        num_layers: int = 8,
        num_heads: int = 16,
        max_seq_len: int = 2048,
        time_steps: int = 40
    ):
        super().__init__()
        self.d_model = d_model
        self.max_seq_len = max_seq_len
        self.time_steps = time_steps
        self.vocab_size = vocab_size
        
        # åŸ‹ã‚è¾¼ã¿å±¤
        self.token_embedding = nn.Embedding(vocab_size, d_model)
        self.position_embedding = nn.Parameter(torch.randn(max_seq_len, d_model) * 0.02)
        
        # å…¥åŠ›å‡¦ç†å±¤
        self.input_projection = AdaptiveSTDPSynapse(d_model, d_model)
        self.input_norm = nn.LayerNorm(d_model)
        
        # é©æ–°çš„ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ãƒ¬ã‚¤ãƒ¤ãƒ¼
        self.layers = nn.ModuleList()
        for i in range(num_layers):
            layer = nn.ModuleDict({
                'ssm': SpikingSSMLayer(d_model, d_state),
                'attention': TemporalSpikeAttention(d_model, num_heads),
                'ffn': self._create_spiking_ffn(d_model),
                'norm1': nn.LayerNorm(d_model),
                'norm2': nn.LayerNorm(d_model),
                'norm3': nn.LayerNorm(d_model)
            })
            self.layers.append(layer)
        
        # å‡ºåŠ›å±¤
        self.output_norm = nn.LayerNorm(d_model)
        self.output_projection = AdaptiveSTDPSynapse(d_model, vocab_size)
        
        # ã‚¹ãƒ‘ã‚¤ã‚¯ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼
        self.spike_encoder = self._create_advanced_spike_encoder()
        
        # ã‚¤ãƒ™ãƒ³ãƒˆé§†å‹•ã‚¨ãƒ³ã‚¸ãƒ³
        self.event_engine = EventDrivenComputeEngine(self, spike_threshold=0.02)
        
        # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç›£è¦–
        self.performance_monitor = PerformanceMonitor()
        
    def _create_spiking_ffn(self, d_model: int) -> nn.Module:
        """é«˜æ€§èƒ½ã‚¹ãƒ‘ã‚¤ã‚­ãƒ³ã‚°FFN"""
        return nn.Sequential(
            AdaptiveSTDPSynapse(d_model, d_model * 4),
            MultiThresholdLIF(d_model * 4),
            nn.Dropout(0.1),
            AdaptiveSTDPSynapse(d_model * 4, d_model),
            MultiThresholdLIF(d_model)
        )
    
    def _create_advanced_spike_encoder(self):
        """é«˜åº¦ãªã‚¹ãƒ‘ã‚¤ã‚¯ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼"""
        return AdvancedSpikeEncoder(self.d_model, self.time_steps)
    
    def forward(
        self, 
        input_ids: torch.Tensor, 
        use_event_driven: bool = True,
        return_spikes: bool = False
    ) -> torch.Tensor:
        """
        é©æ–°çš„ãªå‰å‘ãè¨ˆç®—
        """
        batch_size, seq_len = input_ids.shape
        
        # 1. åŸ‹ã‚è¾¼ã¿ã¨ã‚¹ãƒ‘ã‚¤ã‚¯ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°
        token_emb = self.token_embedding(input_ids)
        pos_emb = self.position_embedding[:seq_len].unsqueeze(0)
        embeddings = self.input_norm(token_emb + pos_emb)
        
        # 2. ã‚¹ãƒ‘ã‚¤ã‚¯ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ç”Ÿæˆ
        spike_sequence = self.spike_encoder.encode_sequence(embeddings)
        # spike_sequence: (batch, time_steps, seq_len, d_model)
        
        # 3. é©æ–°çš„å‡¦ç†ãƒ¬ã‚¤ãƒ¤ãƒ¼
        hidden_states = spike_sequence
        
        for layer in self.layers:
            # Layer normalization
            normed_input = layer['norm1'](hidden_states.mean(dim=1))  # æ™‚é–“å¹³å‡ã§æ­£è¦åŒ–
            
            # Spiking State Space Model
            ssm_out = layer['ssm'](hidden_states)
            hidden_states = hidden_states + ssm_out
            
            # Temporal Spike Attention
            normed_hidden = layer['norm2'](hidden_states.mean(dim=1)).unsqueeze(1).repeat(1, self.time_steps, 1, 1)
            attn_out = layer['attention'](normed_hidden)
            hidden_states = hidden_states + attn_out
            
            # Spiking Feed-Forward
            normed_final = layer['norm3'](hidden_states.mean(dim=1))
            ffn_input = normed_final.unsqueeze(1).repeat(1, self.time_steps, 1, 1)
            ffn_out = self._apply_ffn_to_spikes(layer['ffn'], ffn_input)
            hidden_states = hidden_states + ffn_out
        
        # 4. å‡ºåŠ›å‡¦ç†
        if use_event_driven:
            # ã‚¤ãƒ™ãƒ³ãƒˆé§†å‹•è¨ˆç®—ã§åŠ¹ç‡åŒ–
            final_output = self.event_engine(hidden_states)
        else:
            final_output = hidden_states
        
        # 5. æœ€çµ‚å‡ºåŠ›ç”Ÿæˆ
        # æ™‚é–“æ¬¡å…ƒã§çµ±åˆï¼ˆã‚¹ãƒ‘ã‚¤ã‚¯å¯†åº¦ã‚’è€ƒæ…®ï¼‰
        time_integrated = self._integrate_temporal_spikes(final_output)
        time_integrated = self.output_norm(time_integrated)
        
        # èªå½™ã¸ã®æŠ•å½±
        logits = self.output_projection(time_integrated.reshape(-1, self.d_model))
        logits = logits.reshape(batch_size, seq_len, self.vocab_size)
        
        if return_spikes:
            return logits, final_output
        return logits
    
    def _apply_ffn_to_spikes(self, ffn: nn.Module, spike_input: torch.Tensor) -> torch.Tensor:
        """ã‚¹ãƒ‘ã‚¤ã‚¯ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã«FFNã‚’é©ç”¨"""
        batch_size, time_steps, seq_len, d_model = spike_input.shape
        outputs = []
        
        for t in range(time_steps):
            x_t = spike_input[:, t, :, :].reshape(-1, d_model)
            out_t = ffn(x_t).reshape(batch_size, seq_len, d_model)
            outputs.append(out_t)
        
        return torch.stack(outputs, dim=1)
    
    def _integrate_temporal_spikes(self, spike_sequence: torch.Tensor) -> torch.Tensor:
        """æ™‚é–“æ¬¡å…ƒã®ã‚¹ãƒ‘ã‚¤ã‚¯ã‚’çµ±åˆ"""
        # åŠ é‡å¹³å‡ï¼ˆå¾Œã®æ™‚åˆ»ã«ã‚ˆã‚Šå¤§ããªé‡ã¿ï¼‰
        time_weights = torch.linspace(0.1, 1.0, self.time_steps, device=spike_sequence.device)
        time_weights = time_weights.view(1, -1, 1, 1)
        
        weighted_spikes = spike_sequence * time_weights
        integrated = weighted_spikes.sum(dim=1) / time_weights.sum()
        
        return integrated

class AdvancedSpikeEncoder(nn.Module):
    """æœ€å…ˆç«¯ã‚¹ãƒ‘ã‚¤ã‚¯ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚·ã‚¹ãƒ†ãƒ """
    
    def __init__(self, d_model: int, time_steps: int):
        super().__init__()
        self.d_model = d_model
        self.time_steps = time_steps
        
        # è¤‡æ•°ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°æ‰‹æ³•
        self.encoding_methods = nn.ModuleDict({
            'rate': RateEncoder(d_model, time_steps),
            'temporal': TemporalEncoder(d_model, time_steps),
            'population': PopulationEncoder(d_model, time_steps),
            'phase': PhaseEncoder(d_model, time_steps)
        })
        
        # ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°é‡ã¿
        self.encoding_weights = nn.Parameter(torch.ones(4) / 4)
        
    def encode_sequence(self, embeddings: torch.Tensor) -> torch.Tensor:
        """ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã‚’ã‚¹ãƒ‘ã‚¤ã‚¯åˆ—ã«ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰"""
        batch_size, seq_len, d_model = embeddings.shape
        
        # å„ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°æ‰‹æ³•ã‚’é©ç”¨
        encoded_outputs = {}
        for name, encoder in self.encoding_methods.items():
            encoded_outputs[name] = encoder(embeddings)
        
        # é‡ã¿ä»˜ãçµåˆ
        weights = F.softmax(self.encoding_weights, dim=0)
        final_encoding = torch.zeros(batch_size, self.time_steps, seq_len, d_model, device=embeddings.device)
        
        for i, (name, encoded) in enumerate(encoded_outputs.items()):
            final_encoding += weights[i] * encoded
        
        return final_encoding

class RateEncoder(nn.Module):
    """æ”¹è‰¯ç‰ˆãƒ¬ãƒ¼ãƒˆã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°"""
    def __init__(self, d_model: int, time_steps: int):
        super().__init__()
        self.time_steps = time_steps
        self.noise_scale = 0.1
        
    def forward(self, x: torch.Tensor) -> torch.Tensor:
        batch_size, seq_len, d_model = x.shape
        
        # æ­£è¦åŒ–ã¨ãƒã‚¤ã‚ºè¿½åŠ 
        firing_rates = torch.sigmoid(x) * 0.9 + 0.05
        noise = torch.randn_like(firing_rates) * self.noise_scale
        firing_rates = torch.clamp(firing_rates + noise, 0, 1)
        
        # ã‚¹ãƒ‘ã‚¤ã‚¯ç”Ÿæˆ
        random_vals = torch.rand(batch_size, self.time_steps, seq_len, d_model, device=x.device)
        spikes = (random_vals < firing_rates.unsqueeze(1)).float()
        
        return spikes

class TemporalEncoder(nn.Module):
    """æ™‚é–“çš„ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°"""
    def __init__(self, d_model: int, time_steps: int):
        super().__init__()
        self.time_steps = time_steps
        
    def forward(self, x: torch.Tensor) -> torch.Tensor:
        batch_size, seq_len, d_model = x.shape
        
        # å€¤ã«å¿œã˜ãŸã‚¹ãƒ‘ã‚¤ã‚¯ã‚¿ã‚¤ãƒŸãƒ³ã‚°
        normalized_x = torch.sigmoid(x)
        spike_times = (normalized_x * (self.time_steps - 1)).long()
        
        spikes = torch.zeros(batch_size, self.time_steps, seq_len, d_model, device=x.device)
        
        for b in range(batch_size):
            for s in range(seq_len):
                for d in range(d_model):
                    t = spike_times[b, s, d].item()
                    if 0 <= t < self.time_steps:
                        spikes[b, t, s, d] = 1.0
        
        return spikes

class PopulationEncoder(nn.Module):
    """é›†å›£ã‚¹ãƒ‘ã‚¤ã‚¯ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°"""
    def __init__(self, d_model: int, time_steps: int, num_neurons: int = 8):
        super().__init__()
        self.time_steps = time_steps
        self.num_neurons = num_neurons
        self.population_transform = nn.Linear(d_model, d_model * num_neurons)
        
    def forward(self, x: torch.Tensor) -> torch.Tensor:
        batch_size, seq_len, d_model = x.shape
        
        # é›†å›£ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã¸ã®å¤‰æ›
        population_response = self.population_transform(x)
        population_response = population_response.view(batch_size, seq_len, d_model, self.num_neurons)
        
        # å„ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã®ç™ºç«ç‡
        firing_rates = torch.sigmoid(population_response)
        
        # é›†å›£ã‚¹ãƒ‘ã‚¤ã‚¯ãƒ‘ã‚¿ãƒ¼ãƒ³ç”Ÿæˆ
        random_vals = torch.rand(batch_size, self.time_steps, seq_len, d_model, self.num_neurons, device=x.device)
        population_spikes = (random_vals < firing_rates.unsqueeze(1)).float()
        
        # é›†å›£å¿œç­”ã®çµ±åˆ
        integrated_spikes = population_spikes.mean(dim=-1)  # ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³å¹³å‡
        
        return integrated_spikes

class PhaseEncoder(nn.Module):
    """ä½ç›¸ãƒ™ãƒ¼ã‚¹ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°"""
    def __init__(self, d_model: int, time_steps: int):
        super().__init__()
        self.time_steps = time_steps
        self.frequency_bands = nn.Parameter(torch.linspace(1, 10, d_model))
        
    def forward(self, x: torch.Tensor) -> torch.Tensor:
        batch_size, seq_len, d_model = x.shape
        
        # ä½ç›¸è¨ˆç®—
        phases = torch.sigmoid(x) * 2 * math.pi
        
        # æ™‚é–“è»¸
        t = torch.linspace(0, 2 * math.pi, self.time_steps, device=x.device)
        t = t.view(1, -1, 1, 1)
        
        # å‘¨æ³¢æ•°å¸¯åŸŸ
        freqs = self.frequency_bands.view(1, 1, 1, -1)
        phases_expanded = phases.view(batch_size, 1, seq_len, d_model)
        
        # æ­£å¼¦æ³¢ç”Ÿæˆ
        waves = torch.sin(freqs * t + phases_expanded)
        
        # ã‚¹ãƒ‘ã‚¤ã‚¯ã¸ã®å¤‰æ›
        spikes = (waves > 0.5).float()
        
        return spikes

# ----------------------------------------
# 6. ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç›£è¦–ã‚·ã‚¹ãƒ†ãƒ 
# ----------------------------------------

class PerformanceMonitor:
    """ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ€§èƒ½ç›£è¦–"""
    
    def __init__(self):
        self.metrics = {
            'inference_time': [],
            'energy_estimate': [],
            'spike_rate': [],
            'computation_efficiency': [],
            'memory_usage': []
        }
        self.start_time = None
    
    def start_measurement(self):
        """æ¸¬å®šé–‹å§‹"""
        self.start_time = time.time()
        torch.cuda.reset_peak_memory_stats() if torch.cuda.is_available() else None
    
    def end_measurement(self, model_output: torch.Tensor, spike_data: Optional[torch.Tensor] = None):
        """æ¸¬å®šçµ‚äº†ã¨ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¨˜éŒ²"""
        if self.start_time is None:
            return
        
        # æ¨è«–æ™‚é–“
        inference_time = time.time() - self.start_time
        self.metrics['inference_time'].append(inference_time)
        
        # ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡
        if torch.cuda.is_available():
            memory_usage = torch.cuda.max_memory_allocated() / 1024**3  # GB
            self.metrics['memory_usage'].append(memory_usage)
        
        # ã‚¹ãƒ‘ã‚¤ã‚¯ãƒ¬ãƒ¼ãƒˆï¼ˆæä¾›ã•ã‚Œã¦ã„ã‚‹å ´åˆï¼‰
        if spike_data is not None:
            total_spikes = spike_data.sum().item()
            total_possible = spike_data.numel()
            spike_rate = total_spikes / total_possible if total_possible > 0 else 0
            self.metrics['spike_rate'].append(spike_rate)
            
            # ã‚¨ãƒãƒ«ã‚®ãƒ¼æ¨å®šï¼ˆã‚¹ãƒ‘ã‚¤ã‚¯ãƒ¬ãƒ¼ãƒˆãƒ™ãƒ¼ã‚¹ï¼‰
            # SNNã¯ä½ã‚¹ãƒ‘ã‚¤ã‚¯ãƒ¬ãƒ¼ãƒˆã§é«˜ã‚¨ãƒãƒ«ã‚®ãƒ¼åŠ¹ç‡
            base_energy = 1.0  # åŸºæº–ã‚¨ãƒãƒ«ã‚®ãƒ¼
            energy_estimate = base_energy * spike_rate * 0.1  # å¤§å¹…ãªåŠ¹ç‡åŒ–
            self.metrics['energy_estimate'].append(energy_estimate)
        
        self.start_time = None
    
    def get_summary(self) -> Dict[str, float]:
        """æ€§èƒ½ã‚µãƒãƒªãƒ¼ã®å–å¾—"""
        summary = {}
        for key, values in self.metrics.items():
            if values:
                summary[f'{key}_avg'] = np.mean(values)
                summary[f'{key}_std'] = np.std(values)
                summary[f'{key}_latest'] = values[-1]
        
        return summary
    
    def compare_with_baseline(self, baseline_metrics: Dict[str, float]) -> Dict[str, float]:
        """ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ï¼ˆANNï¼‰ã¨ã®æ¯”è¼ƒ"""
        current = self.get_summary()
        comparison = {}
        
        for key in baseline_metrics:
            if key in current:
                improvement = (baseline_metrics[key] - current[key]) / baseline_metrics[key] * 100
                comparison[f'{key}_improvement_%'] = improvement
        
        return comparison

# ----------------------------------------
# 7. çµ±åˆãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚·ã‚¹ãƒ†ãƒ 
# ----------------------------------------

class BreakthroughTrainer:
    """é©æ–°çš„SNNã®è¨“ç·´ã‚·ã‚¹ãƒ†ãƒ """
    
    def __init__(self, model: BreakthroughSNN, device: str = "cuda"):
        self.model = model.to(device)
        self.device = device
        
        # æœ€é©åŒ–è¨­å®š
        self.optimizer = torch.optim.AdamW(
            self.model.parameters(),
            lr=2e-4,
            weight_decay=0.01,
            betas=(0.9, 0.95)
        )
        
        # å­¦ç¿’ç‡ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼
        self.scheduler = torch.optim.lr_scheduler.OneCycleLR(
            self.optimizer,
            max_lr=2e-4,
            total_steps=10000,
            pct_start=0.1,
            div_factor=25,
            final_div_factor=1e4
        )
        
        # æå¤±é–¢æ•°ï¼ˆè¤‡æ•°ã®æå¤±ã‚’çµ„ã¿åˆã‚ã›ï¼‰
        self.criterion = CombinedLoss()
        
        # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç›£è¦–
        self.monitor = PerformanceMonitor()
        
    def train_step(self, input_ids: torch.Tensor, target_ids: torch.Tensor) -> Dict[str, float]:
        """å˜ä¸€è¨“ç·´ã‚¹ãƒ†ãƒƒãƒ—"""
        self.model.train()
        
        input_ids = input_ids.to(self.device)
        target_ids = target_ids.to(self.device)
        
        # æ¸¬å®šé–‹å§‹
        self.monitor.start_measurement()
        
        # å‰å‘ãè¨ˆç®—
        self.optimizer.zero_grad()
        logits, spike_data = self.model(input_ids, return_spikes=True)
        
        # æå¤±è¨ˆç®—
        loss_dict = self.criterion(logits, target_ids, spike_data)
        total_loss = loss_dict['total']
        
        # é€†ä¼æ’­
        total_loss.backward()
        
        # å‹¾é…ã‚¯ãƒªãƒƒãƒ”ãƒ³ã‚°
        torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)
        
        # æœ€é©åŒ–ã‚¹ãƒ†ãƒƒãƒ—
        self.optimizer.step()
        self.scheduler.step()
        
        # æ¸¬å®šçµ‚äº†
        self.monitor.end_measurement(logits, spike_data)
        
        return {
            'total_loss': total_loss.item(),
            **{k: v.item() if torch.is_tensor(v) else v for k, v in loss_dict.items()},
            'lr': self.scheduler.get_last_lr()[0]
        }

class CombinedLoss(nn.Module):
    """è¤‡æ•°ã®æå¤±é–¢æ•°ã‚’çµ„ã¿åˆã‚ã›ãŸé«˜åº¦ãªæå¤±"""
    
    def __init__(self):
        super().__init__()
        self.ce_loss = nn.CrossEntropyLoss(label_smoothing=0.1)
        
        # æå¤±ã®é‡ã¿
        self.weights = {
            'ce': 1.0,          # ã‚¯ãƒ­ã‚¹ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼
            'spike_reg': 0.01,  # ã‚¹ãƒ‘ã‚¤ã‚¯æ­£å‰‡åŒ–
            'energy_reg': 0.001 # ã‚¨ãƒãƒ«ã‚®ãƒ¼æ­£å‰‡åŒ–
        }
    
    def forward(self, logits: torch.Tensor, targets: torch.Tensor, spikes: torch.Tensor) -> Dict[str, torch.Tensor]:
        """çµ±åˆæå¤±ã®è¨ˆç®—"""
        # åŸºæœ¬çš„ãªã‚¯ãƒ­ã‚¹ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼æå¤±
        ce_loss = self.ce_loss(logits.view(-1, logits.size(-1)), targets.view(-1))
        
        # ã‚¹ãƒ‘ã‚¤ã‚¯æ­£å‰‡åŒ–ï¼ˆé©åº¦ãªã‚¹ãƒ‘ã‚¤ã‚¯ãƒ¬ãƒ¼ãƒˆã‚’ä¿ƒé€²ï¼‰
        spike_rate = spikes.mean()
        target_spike_rate = 0.1  # ç›®æ¨™ã‚¹ãƒ‘ã‚¤ã‚¯ãƒ¬ãƒ¼ãƒˆ
        spike_reg = torch.abs(spike_rate - target_spike_rate)
        
        # ã‚¨ãƒãƒ«ã‚®ãƒ¼æ­£å‰‡åŒ–ï¼ˆä½ã‚¨ãƒãƒ«ã‚®ãƒ¼æ¶ˆè²»ã‚’ä¿ƒé€²ï¼‰
        energy_reg = spike_rate * spikes.var()  # åˆ†æ•£ã‚‚è€ƒæ…®
        
        # ç·æå¤±
        total_loss = (
            self.weights['ce'] * ce_loss +
            self.weights['spike_reg'] * spike_reg +
            self.weights['energy_reg'] * energy_reg
        )
        
        return {
            'total': total_loss,
            'ce': ce_loss,
            'spike_reg': spike_reg,
            'energy_reg': energy_reg,
            'spike_rate': spike_rate
        }

# ----------------------------------------
# 8. ä½¿ç”¨ä¾‹ã¨ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯
# ----------------------------------------

def main_breakthrough_training():
    """ãƒ¡ã‚¤ãƒ³ã®è¨“ç·´ãƒ«ãƒ¼ãƒãƒ³"""
    print("ğŸš€ é©æ–°çš„SNNã‚·ã‚¹ãƒ†ãƒ ã®è¨“ç·´é–‹å§‹")
    
    # ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã®æº–å‚™
    sample_conversations = [
        ("What is artificial intelligence", "AI is intelligence demonstrated by machines"),
        ("How do neural networks work", "Neural networks process information through connected nodes"),
        ("Explain deep learning", "Deep learning uses multiple layers to learn complex patterns"),
        ("What makes SNNs special", "SNNs process information using spikes like biological neurons"),
        ("Why is energy efficiency important", "Energy efficiency enables AI on mobile and edge devices"),
        ("How can AI help society", "AI can improve healthcare education and scientific research"),
        ("What is the future of computing", "Neuromorphic computing mimics brain-like information processing"),
        ("Describe machine learning", "Machine learning allows systems to learn from data without programming"),
    ]
    
    # èªå½™æ§‹ç¯‰ï¼ˆç°¡æ˜“ç‰ˆï¼‰
    all_texts = [text for conv in sample_conversations for text in conv]
    vocab = build_simple_vocab(all_texts)
    
    # ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–
    model = BreakthroughSNN(
        vocab_size=len(vocab),
        d_model=256,          # å°ã•ã‚ã‹ã‚‰é–‹å§‹
        num_layers=4,
        time_steps=20
    )
    
    print(f"ãƒ¢ãƒ‡ãƒ«ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°: {sum(p.numel() for p in model.parameters()):,}")
    
    # ãƒˆãƒ¬ãƒ¼ãƒŠãƒ¼åˆæœŸåŒ–
    trainer = BreakthroughTrainer(model)
    
    # è¨“ç·´ãƒ‡ãƒ¼ã‚¿æº–å‚™
    train_data = prepare_training_data(sample_conversations, vocab)
    
    # è¨“ç·´ãƒ«ãƒ¼ãƒ—
    for epoch in range(5):  # çŸ­ã„è¨“ç·´
        total_loss = 0
        num_batches = 0
        
        for batch in train_data:
            input_ids, target_ids = batch
            
            # è¨“ç·´ã‚¹ãƒ†ãƒƒãƒ—
            metrics = trainer.train_step(input_ids, target_ids)
            total_loss += metrics['total_loss']
            num_batches += 1
            
            if num_batches % 5 == 0:
                print(f"Epoch {epoch}, Batch {num_batches}: {metrics}")
        
        avg_loss = total_loss / num_batches if num_batches > 0 else 0
        print(f"âœ… Epoch {epoch} å®Œäº† - å¹³å‡æå¤±: {avg_loss:.4f}")
    
    # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚µãƒãƒªãƒ¼
    performance_summary = trainer.monitor.get_summary()
    print("\nğŸ“Š ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚µãƒãƒªãƒ¼:")
    for key, value in performance_summary.items():
        print(f"  {key}: {value:.4f}")
    
    print("\nğŸ‰ é©æ–°çš„SNNã®è¨“ç·´å®Œäº†ï¼")

def build_simple_vocab(texts: List[str]) -> Dict[str, int]:
    """ç°¡æ˜“èªå½™æ§‹ç¯‰"""
    vocab = {"<PAD>": 0, "<UNK>": 1, "<START>": 2, "<END>": 3}
    
    for text in texts:
        for word in text.lower().split():
            if word not in vocab:
                vocab[word] = len(vocab)
    
    return vocab

def prepare_training_data(conversations: List[Tuple[str, str]], vocab: Dict[str, int], max_len: int = 32):
    """è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã®æº–å‚™"""
    def encode_text(text: str) -> List[int]:
        return [vocab.get(word.lower(), vocab["<UNK>"]) for word in text.split()]
    
    data_pairs = []
    for input_text, target_text in conversations:
        input_ids = encode_text(input_text)[:max_len-1] + [vocab["<END>"]]
        target_ids = encode_text(target_text)[:max_len-1] + [vocab["<END>"]]
        
        # ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°
        input_ids += [vocab["<PAD>"]] * (max_len - len(input_ids))
        target_ids += [vocab["<PAD>"]] * (max_len - len(target_ids))
        
        data_pairs.append((
            torch.tensor(input_ids[:max_len]),
            torch.tensor(target_ids[:max_len])
        ))
    
    return data_pairs

if __name__ == "__main__":
    main_breakthrough_training()